## 2.1.1 tf.keras.layers

### 라이브러리 불러오기 및 상수값 설정


```python
import tensorflow as tf
```


```python
INPUT_SIZE = (20, 1)
CONV_INPUT_SIZE = (1, 28, 28)
IS_TRAINING = True
```

### Dense Layer


```python
input = tf.placeholder(tf.float32, shape = INPUT_SIZE)
output = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(input) 
```

### Dense Layer with 1 hidden layer


```python
input = tf.placeholder(tf.float32, shape = INPUT_SIZE)
hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(input)
output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)
```

### Dropout


```python
input = tf.placeholder(tf.float32, shape = INPUT_SIZE)
dropout = tf.keras.layers.Dropout(rate = 0.5)(input)
```

### Dense Layer with 1 hidden layer and dropout


```python
input = tf.placeholder(tf.float32, shape = INPUT_SIZE)
dropout = tf.keras.layers.Dropout(rate = 0.2)(input)
hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(dropout)
output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)
```

### Convolutional layer


```python
input = tf.placeholder(tf.float32, shape = CONV_INPUT_SIZE)
conv = tf.keras.layers.Conv1D(
         filters=10,
         kernel_size=3,
         padding='same',
         activation=tf.nn.relu)(input)
```

### Convolutional layer with dropout


```python
input = tf.placeholder(tf.float32, shape = CONV_INPUT_SIZE)
dropout = tf.keras.layers.Dropout(rate=0.2)(input)
conv = tf.keras.layers.Conv1D(
         filters=10,
         kernel_size=3,
         padding='same',
         activation=tf.nn.relu)(dropout)

```

### Input -> Dropout -> Convolutional layer -> MaxPooling -> Dense layer with 1 hidden layer -> Output


```python
input = tf.placeholder(tf.float32, shape = CONV_INPUT_SIZE)
dropout = tf.keras.layers.Dropout(rate = 0.2)(input)
conv = tf.keras.layers.Conv1D(
         filters=10,
         kernel_size=3,
         padding='same',
         activation=tf.nn.relu)(dropout)
max_pool = tf.keras.layers.MaxPool1D(pool_size = 3, padding = 'same')(conv)
flatten = tf.keras.layers.Flatten()(max_pool)
hidden = tf.keras.layers.Dense(units = 50, activation = tf.nn.relu)(flatten)
output = tf.keras.layers.Dense(units = 10, activation = tf.nn.softmax)(hidden)  
```


```python

```
